import streamlit as st
import numpy as np
import plotly.graph_objects as go
import pandas as pd

PROBS = [0.4, 0.5, 0.6]
N_ARMS = len(PROBS)
MULTIPLICADOR_VISITANTES = 1000  # Fixo, sem sidebar

class ThompsonSamplingMAB:
    def __init__(self, n_arms):
        self.n_arms = n_arms
        self.successes = np.zeros(n_arms)
        self.failures = np.zeros(n_arms)
        self.counts = np.zeros(n_arms)
        self.values = np.zeros(n_arms)

    def select_arm(self):
        samples = [np.random.beta(self.successes[i] + 1, self.failures[i] + 1) for i in range(self.n_arms)]
        return int(np.argmax(samples))

    def update(self, arm, reward):
        self.counts[arm] += 1
        if reward:
            self.successes[arm] += 1
        else:
            self.failures[arm] += 1
        self.values[arm] = self.successes[arm] / self.counts[arm] if self.counts[arm] > 0 else 0

st.set_page_config(page_title="MAB Simulador", layout="centered")
st.title("üé∞ Simulador Multi-Armed Bandit (MAB) - Thompson Sampling")

# Introdu√ß√£o did√°tica em um expander
with st.expander("Como funciona este simulador? (clique para ver/ocultar)"):
    st.markdown("""
    Imagine que voc√™ √© respons√°vel por um site e quer descobrir qual de tr√™s op√ß√µes (por exemplo, tr√™s banners, layouts ou promo√ß√µes) gera mais cliques ou convers√µes.

    Cada bot√£o abaixo representa uma dessas op√ß√µes. A cada clique, voc√™ simula a escolha de um visitante do site. O algoritmo **Multi-Armed Bandit** (MAB) vai aprendendo, com base nos resultados dos cliques, qual op√ß√£o parece ser a mais eficiente.

    O modelo equilibra **explora√ß√£o** (testar todas as op√ß√µes para aprender) e **aproveitamento** (focar na op√ß√£o que est√° performando melhor at√© agora).

    Os gr√°ficos mostram, de forma visual, como o modelo distribui o tr√°fego entre as op√ß√µes e como ele aprende ao longo do tempo.
    **Cada clique simula 1000 visitantes para deixar a visualiza√ß√£o mais interessante!**

    _Observa√ß√£o:_ Conforme o n√∫mero de cliques aumenta, a **taxa de sucesso estimada** de cada op√ß√£o tende a se estabilizar. Isso significa que, quanto mais dados o modelo coleta, mais dif√≠cil fica mudar a estimativa ‚Äî afinal, ele est√° mais confiante sobre o desempenho de cada op√ß√£o. Por isso, mudan√ßas bruscas nas taxas s√£o mais comuns no in√≠cio, quando h√° poucos dados, e v√£o ficando raras √† medida que o experimento avan√ßa.
    """)

if 'mab' not in st.session_state:
    st.session_state.mab = ThompsonSamplingMAB(N_ARMS)
    st.session_state.history = []  # (botao, reward)
    st.session_state.cumulative_rewards = []

if st.button("Resetar experimento"):
    st.session_state.mab = ThompsonSamplingMAB(N_ARMS)
    st.session_state.history = []
    st.session_state.cumulative_rewards = []

# Sugest√£o do modelo
suggested = st.session_state.mab.select_arm()
taxa = st.session_state.mab.values[suggested]
st.markdown(f"<span style='color:lime;font-weight:bold'>Sugest√£o do modelo (Thompson): Bot√£o {suggested+1} (taxa estimada: {taxa:.2f})</span>", unsafe_allow_html=True)

st.markdown("Clique em qualquer bot√£o abaixo para simular um visitante:")

cols = st.columns(N_ARMS)
clicked = None
for i, col in enumerate(cols):
    if col.button(f"Bot√£o {i+1}"):
        clicked = i

if clicked is not None:
    reward = int(np.random.rand() < PROBS[clicked])
    st.session_state.mab.update(clicked, reward)
    st.session_state.history.append((clicked, reward))
    total_rewards = sum([h[1] for h in st.session_state.history])
    st.session_state.cumulative_rewards.append(
        total_rewards / len(st.session_state.history)
    )

# Gr√°fico de √°rea empilhada: escolhas por rodada (visual multiplicado)
st.markdown("#### Distribui√ß√£o de tr√°fego (escolhas do modelo) ao longo do tempo")
if len(st.session_state.history) > 0:
    df = pd.DataFrame(0, index=np.arange(len(st.session_state.history)), columns=[f"Bot√£o {i+1}" for i in range(N_ARMS)])
    for idx, (botao, _) in enumerate(st.session_state.history):
        df.iloc[idx, botao] = 1
    df_cumsum = df.cumsum()
    x_vis = (df_cumsum.index + 1) * MULTIPLICADOR_VISITANTES
    fig_area = go.Figure()
    for col in df.columns[::-1]:
        fig_area.add_trace(go.Scatter(
            x=x_vis,
            y=df_cumsum[col] * MULTIPLICADOR_VISITANTES,
            mode='lines',
            stackgroup='one',
            name=col
        ))
    fig_area.update_layout(
        xaxis_title="Visitantes simulados",
        yaxis_title="Tr√°fego acumulado",
        legend_title="Bot√£o",
        height=350,
        margin=dict(l=20, r=20, t=30, b=20)
    )
    st.plotly_chart(fig_area, use_container_width=True)

# Gr√°fico de linha: evolu√ß√£o da taxa de sucesso m√©dia (visual multiplicado)
if st.session_state.cumulative_rewards:
    st.markdown("#### Evolu√ß√£o da taxa de sucesso m√©dia")
    x_cum = np.arange(1, len(st.session_state.cumulative_rewards) + 1) * MULTIPLICADOR_VISITANTES
    fig3 = go.Figure()
    fig3.add_trace(go.Scatter(
        x=x_cum,
        y=st.session_state.cumulative_rewards,
        mode='lines+markers',
        name='Taxa m√©dia'
    ))
    fig3.update_layout(
        xaxis_title="Visitantes simulados",
        yaxis_title="Taxa de sucesso m√©dia",
        yaxis=dict(range=[0, 1]),
        height=300,
        margin=dict(l=20, r=20, t=30, b=20)
    )
    st.plotly_chart(fig3, use_container_width=True)


# Gr√°fico de barras: taxa de sucesso estimada
st.markdown("#### Taxa de sucesso estimada por bot√£o")
fig2 = go.Figure()
fig2.add_trace(go.Bar(
    x=[f"Bot√£o {i+1}" for i in range(N_ARMS)],
    y=st.session_state.mab.values,
    marker_color=['#1f77b4', '#ff7f0e', '#2ca02c']
))
fig2.update_layout(
    yaxis=dict(range=[0, 1]),
    height=300,
    margin=dict(l=20, r=20, t=30, b=20)
)
st.plotly_chart(fig2, use_container_width=True)

# Tabela de dados simulados por bot√£o
st.markdown("#### Dados simulados por bot√£o")
dados = {
    "Bot√£o": [f"Bot√£o {i+1}" for i in range(N_ARMS)],
    "Visitantes simulados": [int(st.session_state.mab.counts[i] * MULTIPLICADOR_VISITANTES) for i in range(N_ARMS)],
    "Sucessos simulados": [int(st.session_state.mab.successes[i] * MULTIPLICADOR_VISITANTES) for i in range(N_ARMS)],
    "Taxa de sucesso estimada": [f"{st.session_state.mab.values[i]:.2%}" for i in range(N_ARMS)]
}
st.table(pd.DataFrame(dados))

with st.expander("Como funciona o Thompson Sampling?"):
    st.markdown("""
    **O que √© este simulador?**

    - Cada clique simula a escolha de um bot√£o por 1000 visitantes fict√≠cios.
    - O objetivo do modelo √© aprender, ao longo do tempo, qual bot√£o tem maior chance de sucesso.
    - O algoritmo Thompson Sampling mant√©m uma distribui√ß√£o de probabilidade (Beta) para cada bot√£o, baseada nos sucessos e fracassos observados.
    - A cada rodada, ele sorteia uma probabilidade para cada bot√£o e escolhe aquele com maior valor sorteado, equilibrando explora√ß√£o e aproveitamento.
    - Isso faz com que o modelo aprenda de forma mais est√°vel e realista, mesmo com poucos dados.
    - Os gr√°ficos mostram como o tr√°fego e as taxas de sucesso evoluem conforme o modelo aprende.
    - Os n√∫meros exibidos s√£o multiplicados por 1000 apenas para visualiza√ß√£o, mas o aprendizado do modelo √© feito clique a clique.

    **Sobre a estabiliza√ß√£o das taxas:**
    Conforme o n√∫mero de cliques aumenta, a taxa de sucesso estimada de cada op√ß√£o tende a se estabilizar. Isso acontece porque, com mais dados, o modelo fica mais confiante sobre o desempenho de cada bot√£o. Mudan√ßas bruscas nas taxas s√£o comuns no in√≠cio, mas v√£o ficando raras √† medida que o experimento avan√ßa.
    """)

# Rodap√© com LinkedIn e autoria (ajuste o link abaixo para o seu reposit√≥rio)
st.markdown("""
<br>
<hr style="border:1px solid #444;">
<div style="display:flex; align-items:center; justify-content:center;">
    <img src="https://raw.githubusercontent.com/SEU_USUARIO/SEU_REPOSITORIO/main/LinkedIn_logo_initials.png" width="32" style="margin-right:10px; vertical-align:middle;">
    <a href="https://www.linkedin.com/in/lucas-barbosa-a00302167/" target="_blank" style="font-size:17px; text-decoration:none; color:#0e76a8; font-weight:bold;">
        Desenvolvido por Lucas Barbosa
    </a>
</div>
""", unsafe_allow_html=True)